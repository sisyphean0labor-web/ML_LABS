{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6f8b40d1e9859a",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 Кирюхин Георгий Владимирович М8О-310Б-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd6a9ce2394941",
   "metadata": {},
   "source": [
    "# Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a095f2baf9532c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:26.163356Z",
     "start_time": "2025-12-02T18:48:26.154335Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766bf3b80d129f9",
   "metadata": {},
   "source": [
    "# Анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc978e4abc2ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.656172Z",
     "start_time": "2025-12-02T18:48:26.184996Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')\n",
    "testing_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training dataset size: {training_data.shape}\")\n",
    "print(f\"Testing dataset size: {testing_data.shape}\")\n",
    "print(\"\\nFirst rows of dataset:\")\n",
    "print(training_data.head(4))\n",
    "\n",
    "# EXPLORATORY DATA ANALYSIS (EDA)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(training_data.isnull().sum())\n",
    "\n",
    "# Target variable plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(training_data['RiskScore'], bins=50, edgecolor='black')\n",
    "plt.xlabel('RiskScore')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Target Variable RiskScore')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRiskScore statistics:\")\n",
    "print(f\"Mean: {training_data['RiskScore'].mean():.2f}\")\n",
    "print(f\"Median: {training_data['RiskScore'].median():.2f}\")\n",
    "print(f\"Standard deviation: {training_data['RiskScore'].std():.2f}\")\n",
    "print(f\"Min: {training_data['RiskScore'].min():.2f}, Max: {training_data['RiskScore'].max():.2f}\")\n",
    "\n",
    "# Correlation matrix\n",
    "numeric_columns = training_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "correlation_matrix = training_data[numeric_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0,\n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if 'RiskScore' in correlation_matrix.columns:\n",
    "    target_correlation = correlation_matrix['RiskScore'].abs().sort_values(ascending=False)\n",
    "    print(\"\\nTop-10 features by correlation with RiskScore:\")\n",
    "    print(target_correlation.head(11))\n",
    "\n",
    "important_features = target_correlation.index[1:5]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for index, feature in enumerate(important_features):\n",
    "    axes[index].scatter(training_data[feature], training_data['RiskScore'], alpha=0.5, s=10)\n",
    "    axes[index].set_xlabel(feature)\n",
    "    axes[index].set_ylabel('RiskScore')\n",
    "    axes[index].set_title(f'Relationship: RiskScore vs {feature}')\n",
    "    axes[index].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b7a17b0db1157",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cf2ee98f52a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.682182Z",
     "start_time": "2025-12-02T18:48:30.671224Z"
    }
   },
   "outputs": [],
   "source": [
    "def mse_custom(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mae_custom(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def r2_custom(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def mape_custom(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0433ef6a82e2f1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.795090Z",
     "start_time": "2025-12-02T18:48:30.774958Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true_test = np.array([3, -0.5, 2, 7])\n",
    "y_pred_test = np.array([2.5, 0.0, 2, 8])\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(f\"y_true: {y_true_test}\")\n",
    "print(f\"y_pred: {y_pred_test}\")\n",
    "\n",
    "print(\"\\nMSE:\")\n",
    "print(f\"Custom implementation: {mse_custom(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Sklearn:               {mean_squared_error(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Difference:            {abs(mse_custom(y_true_test, y_pred_test) - mean_squared_error(y_true_test, y_pred_test)):.4f}\")\n",
    "\n",
    "print(\"\\nMAE:\")\n",
    "print(f\"Custom implementation: {mae_custom(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Sklearn:               {mean_absolute_error(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Difference:            {abs(mae_custom(y_true_test, y_pred_test) - mean_absolute_error(y_true_test, y_pred_test)):.4f}\")\n",
    "\n",
    "print(\"\\nR²:\")\n",
    "print(f\"Custom implementation: {r2_custom(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Sklearn:               {r2_score(y_true_test, y_pred_test):.6f}\")\n",
    "print(f\"Difference:            {abs(r2_custom(y_true_test, y_pred_test) - r2_score(y_true_test, y_pred_test)):.4f}\")\n",
    "\n",
    "print(\"\\nMAPE:\")\n",
    "print(f\"Custom implementation: {mape_custom(y_true_test, y_pred_test):.6f}%\")\n",
    "print(f\"Sklearn:               {(mean_absolute_percentage_error(y_true_test, y_pred_test) * 100):.6f}%\")\n",
    "print(f\"Difference:            {abs(mape_custom(y_true_test, y_pred_test) - mean_absolute_percentage_error(y_true_test, y_pred_test) * 100):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67cc90bb61a5b2c",
   "metadata": {},
   "source": [
    "# Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75105a20efe3ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.844538Z",
     "start_time": "2025-12-02T18:48:30.832748Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataNormalizer:\n",
    "    def __init__(self, method='zscore'):\n",
    "        self.method = method\n",
    "        self.params = {}\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.method == 'zscore':\n",
    "            self.params['mean'] = np.mean(X, axis=0)\n",
    "            self.params['std'] = np.std(X, axis=0)\n",
    "        elif self.method == 'minmax':\n",
    "            self.params['min'] = np.min(X, axis=0)\n",
    "            self.params['max'] = np.max(X, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.method == 'zscore':\n",
    "            std = self.params['std'].copy()\n",
    "            std[std == 0] = 1\n",
    "            return (X - self.params['mean']) / std\n",
    "        elif self.method == 'minmax':\n",
    "            range_val = self.params['max'] - self.params['min']\n",
    "            range_val[range_val == 0] = 1\n",
    "            return (X - self.params['min']) / range_val\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998a046107d2568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.864642Z",
     "start_time": "2025-12-02T18:48:30.853059Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\nTest data:\")\n",
    "print(test_data)\n",
    "\n",
    "# Z-score normalization\n",
    "normalizer_zscore = DataNormalizer(method='zscore')\n",
    "normalized_zscore = normalizer_zscore.fit_transform(test_data)\n",
    "print(\"\\nZ-score normalization:\")\n",
    "print(normalized_zscore)\n",
    "print(\"Mean:\", np.mean(normalized_zscore, axis=0))\n",
    "print(\"Std:\", np.std(normalized_zscore, axis=0))\n",
    "\n",
    "# Min-Max normalization\n",
    "normalizer_minmax = DataNormalizer(method='minmax')\n",
    "normalized_minmax = normalizer_minmax.fit_transform(test_data)\n",
    "print(\"\\nMin-Max normalization:\")\n",
    "print(normalized_minmax)\n",
    "print(\"Min:\", np.min(normalized_minmax, axis=0))\n",
    "print(\"Max:\", np.max(normalized_minmax, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d7283f946986",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0cb4ab7e6cfdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:30.902109Z",
     "start_time": "2025-12-02T18:48:30.880682Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegressionCustom:\n",
    "    \"\"\"Linear regression class with different training methods\"\"\"\n",
    "\n",
    "    def __init__(self, method='analytical', learning_rate=0.01, n_iterations=1000,\n",
    "                 batch_size=32, regularization=None, lambda_reg=0.01, p_norm=2):\n",
    "        \"\"\"\n",
    "        method: 'analytical', 'gradient_descent', 'sgd'\n",
    "        regularization: None, 'l1', 'l2', 'elastic', 'lp'\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.regularization = regularization\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.p_norm = p_norm\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Model training\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if self.method == 'analytical':\n",
    "            self._fit_analytical(X, y)\n",
    "        elif self.method == 'gradient_descent':\n",
    "            self._fit_gradient_descent(X, y)\n",
    "        elif self.method == 'sgd':\n",
    "            self._fit_sgd(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit_analytical(self, X, y):\n",
    "        \"\"\"Analytical solution via normal equation\"\"\"\n",
    "        # Add column of ones for bias\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "        if self.regularization == 'l2':\n",
    "            # Ridge regression: (X^T X + λI)^-1 X^T y\n",
    "            I = np.eye(X_b.shape[1])\n",
    "            I[0, 0] = 0  # Don't regularize bias\n",
    "            # Use pinv for better stability\n",
    "            theta = np.linalg.pinv(X_b.T @ X_b + self.lambda_reg * I) @ X_b.T @ y\n",
    "        else:\n",
    "            # Regular regression: (X^T X)^-1 X^T y\n",
    "            # Use pinv instead of inv for better stability (as in lab1.ipynb)\n",
    "            theta = np.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\n",
    "        self.bias = theta[0]\n",
    "        self.weights = theta[1:]\n",
    "\n",
    "    def _fit_gradient_descent(self, X, y):\n",
    "        \"\"\"Gradient descent\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            # Predictions\n",
    "            y_pred = X @ self.weights + self.bias\n",
    "\n",
    "            # Gradients\n",
    "            dw = (1 / n_samples) * (X.T @ (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Add regularization to gradients\n",
    "            if self.regularization == 'l1':\n",
    "                dw += self.lambda_reg * np.sign(self.weights)\n",
    "            elif self.regularization == 'l2':\n",
    "                dw += 2 * self.lambda_reg * self.weights\n",
    "            elif self.regularization == 'elastic':\n",
    "                dw += self.lambda_reg * (0.5 * np.sign(self.weights) + self.weights)\n",
    "            elif self.regularization == 'lp':\n",
    "                dw += self.lambda_reg * self.p_norm * np.sign(self.weights) * (\n",
    "                        np.abs(self.weights) ** (self.p_norm - 1))\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Save loss\n",
    "            if iteration % 100 == 0:\n",
    "                loss = mse_custom(y, y_pred)\n",
    "                self.loss_history.append(loss)\n",
    "\n",
    "    def _fit_sgd(self, X, y):\n",
    "        \"\"\"Stochastic gradient descent\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            # Shuffle data\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            # Mini-batches\n",
    "            for i in range(0, n_samples, self.batch_size):\n",
    "                X_batch = X_shuffled[i:i + self.batch_size]\n",
    "                y_batch = y_shuffled[i:i + self.batch_size]\n",
    "\n",
    "                # Predictions\n",
    "                y_pred = X_batch @ self.weights + self.bias\n",
    "\n",
    "                # Gradients\n",
    "                batch_size_actual = X_batch.shape[0]\n",
    "                dw = (1 / batch_size_actual) * (X_batch.T @ (y_pred - y_batch))\n",
    "                db = (1 / batch_size_actual) * np.sum(y_pred - y_batch)\n",
    "\n",
    "                # Add regularization\n",
    "                if self.regularization == 'l1':\n",
    "                    dw += self.lambda_reg * np.sign(self.weights)\n",
    "                elif self.regularization == 'l2':\n",
    "                    dw += 2 * self.lambda_reg * self.weights\n",
    "                elif self.regularization == 'elastic':\n",
    "                    dw += self.lambda_reg * (0.5 * np.sign(self.weights) + self.weights)\n",
    "                elif self.regularization == 'lp':\n",
    "                    dw += self.lambda_reg * self.p_norm * np.sign(self.weights) * (\n",
    "                            np.abs(self.weights) ** (self.p_norm - 1))\n",
    "\n",
    "                # Update\n",
    "                self.weights -= self.learning_rate * dw\n",
    "                self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Save loss\n",
    "            if iteration % 100 == 0:\n",
    "                y_pred_all = X @ self.weights + self.bias\n",
    "                loss = mse_custom(y, y_pred_all)\n",
    "                self.loss_history.append(loss)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction\"\"\"\n",
    "        return X @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc9a96bb886f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.041814Z",
     "start_time": "2025-12-02T18:48:30.913260Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_simple = np.random.randn(100, 3)\n",
    "y_simple = 3 * X_simple[:, 0] + 2 * X_simple[:, 1] - X_simple[:, 2] + 5 + np.random.randn(100) * 0.1\n",
    "\n",
    "methods = ['analytical', 'gradient_descent', 'sgd']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'analytical':\n",
    "        model = LinearRegressionCustom(method=method)\n",
    "    else:\n",
    "        model = LinearRegressionCustom(method=method, learning_rate=0.1, n_iterations=1000)\n",
    "\n",
    "    model.fit(X_simple, y_simple)\n",
    "    y_pred = model.predict(X_simple)\n",
    "    mse = mse_custom(y_simple, y_pred)\n",
    "    results[method] = mse\n",
    "\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  Weights: {model.weights}\")\n",
    "    print(f\"  Bias: {model.bias:.4f}\")\n",
    "\n",
    "# Сравнение со sklearn\n",
    "print(\"\\nSKLEARN:\")\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_simple, y_simple)\n",
    "y_pred_sklearn = sklearn_model.predict(X_simple)\n",
    "mse_sklearn = mean_squared_error(y_simple, y_pred_sklearn)\n",
    "print(f\"  MSE: {mse_sklearn:.6f}\")\n",
    "print(f\"  Weights: {sklearn_model.coef_}\")\n",
    "print(f\"  Bias: {sklearn_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901b29b5b133f3f",
   "metadata": {},
   "source": [
    "# Кроссвалидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550583254fe74afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.074713Z",
     "start_time": "2025-12-02T18:48:31.060477Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    \"\"\"Class for cross-validation\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def k_fold(X, y, k=5):\n",
    "        \"\"\"K-Fold cross-validation\"\"\"\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        fold_size = n_samples // k\n",
    "        folds = []\n",
    "\n",
    "        for i in range(k):\n",
    "            start_idx = i * fold_size\n",
    "            end_idx = start_idx + fold_size if i < k - 1 else n_samples\n",
    "\n",
    "            test_indices = indices[start_idx:end_idx]\n",
    "            train_indices = np.concatenate([indices[:start_idx], indices[end_idx:]])\n",
    "\n",
    "            folds.append({\n",
    "                'train': (X[train_indices], y[train_indices]),\n",
    "                'test': (X[test_indices], y[test_indices])\n",
    "            })\n",
    "\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def leave_one_out(X, y):\n",
    "        \"\"\"Leave-One-Out cross-validation\"\"\"\n",
    "        n_samples = len(X)\n",
    "        folds = []\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            test_indices = [i]\n",
    "            train_indices = list(range(i)) + list(range(i + 1, n_samples))\n",
    "\n",
    "            folds.append({\n",
    "                'train': (X[train_indices], y[train_indices]),\n",
    "                'test': (X[[i]], y[[i]])\n",
    "            })\n",
    "\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model, folds, metric_func=mse_custom):\n",
    "        \"\"\"Model evaluation on folds\"\"\"\n",
    "        scores = []\n",
    "\n",
    "        for fold in folds:\n",
    "            X_train, y_train = fold['train']\n",
    "            X_test, y_test = fold['test']\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate metric\n",
    "            score = metric_func(y_test, y_pred)\n",
    "            scores.append(score)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c362cd0f6f06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.124700Z",
     "start_time": "2025-12-02T18:48:31.085302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing cross-validation\n",
    "print(\"\\nTesting K-Fold:\")\n",
    "folds_kfold = CrossValidation.k_fold(X_simple, y_simple, k=5)\n",
    "print(f\"Number of folds: {len(folds_kfold)}\")\n",
    "\n",
    "model = LinearRegressionCustom(method='analytical')\n",
    "scores = CrossValidation.evaluate(model, folds_kfold, mse_custom)\n",
    "print(f\"MSE per fold: {[f'{s:.4f}' for s in scores]}\")\n",
    "print(f\"Average MSE: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "\n",
    "# Comparison with sklearn KFold\n",
    "print(\"\\nComparison with sklearn KFold:\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_scores = -cross_val_score(sklearn_model, X_simple, y_simple,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Sklearn MSE: {np.mean(sklearn_scores):.4f} ± {np.std(sklearn_scores):.4f}\")\n",
    "\n",
    "print(\"\\nTesting Leave-One-Out:\")\n",
    "X_small = X_simple[:20]\n",
    "y_small = y_simple[:20]\n",
    "folds_loo = CrossValidation.leave_one_out(X_small, y_small)\n",
    "print(f\"Number of folds: {len(folds_loo)}\")\n",
    "\n",
    "model = LinearRegressionCustom(method='analytical')\n",
    "scores_loo = CrossValidation.evaluate(model, folds_loo, mse_custom)\n",
    "print(f\"Average MSE (LOO): {np.mean(scores_loo):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89554e908ae7566b",
   "metadata": {},
   "source": [
    "# Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d53258fb2ed5fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.705768Z",
     "start_time": "2025-12-02T18:48:31.149551Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates()\n",
    "test_df = test_df.drop_duplicates()\n",
    "\n",
    "if train_df['RiskScore'].isnull().sum() > 0:\n",
    "    train_df = train_df.dropna(subset=['RiskScore'])\n",
    "\n",
    "Q1 = train_df['RiskScore'].quantile(0.25)\n",
    "Q3 = train_df['RiskScore'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = (train_df['RiskScore'] >= lower_bound) & (train_df['RiskScore'] <= upper_bound)\n",
    "removed_count = (~outlier_mask).sum()\n",
    "train_df = train_df[outlier_mask].reset_index(drop=True)\n",
    "\n",
    "if 'ApplicationDate' in train_df.columns:\n",
    "    train_df['ApplicationDate'] = pd.to_datetime(train_df['ApplicationDate'], errors='coerce')\n",
    "    train_df['ApplicationYear'] = train_df['ApplicationDate'].dt.year\n",
    "    train_df['ApplicationMonth'] = train_df['ApplicationDate'].dt.month\n",
    "    train_df['ApplicationDay'] = train_df['ApplicationDate'].dt.day\n",
    "    train_df = train_df.drop('ApplicationDate', axis=1)\n",
    "\n",
    "if 'ApplicationDate' in test_df.columns:\n",
    "    test_df['ApplicationDate'] = pd.to_datetime(test_df['ApplicationDate'], errors='coerce')\n",
    "    test_df['ApplicationYear'] = test_df['ApplicationDate'].dt.year\n",
    "    test_df['ApplicationMonth'] = test_df['ApplicationDate'].dt.month\n",
    "    test_df['ApplicationDay'] = test_df['ApplicationDate'].dt.day\n",
    "    test_df = test_df.drop('ApplicationDate', axis=1)\n",
    "\n",
    "X_train = train_df.drop('RiskScore', axis=1)\n",
    "y_train = train_df['RiskScore'].values\n",
    "X_test = test_df.copy()\n",
    "\n",
    "test_ids = X_test['id'] if 'id' in X_test.columns else None\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "if 'id' in X_train.columns:\n",
    "    X_train = X_train.drop('id', axis=1)\n",
    "if 'id' in X_test.columns:\n",
    "    X_test = X_test.drop('id', axis=1)\n",
    "\n",
    "# Заполняем пропущенные значения медианой для численных\n",
    "for col in numeric_cols:\n",
    "    if col in X_train.columns and X_train[col].isnull().sum() > 0:\n",
    "        median_val = X_train[col].median()\n",
    "        if pd.isna(median_val):\n",
    "            median_val = 0\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        if col in X_test.columns:\n",
    "            X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Заполняем пропущенные значения модой для категориальных\n",
    "for col in non_numeric_cols:\n",
    "    if col in X_train.columns and X_train[col].isnull().sum() > 0:\n",
    "        mode_val = X_train[col].mode()[0] if len(X_train[col].mode()) > 0 else 'Unknown'\n",
    "        X_train[col].fillna(mode_val, inplace=True)\n",
    "        if col in X_test.columns:\n",
    "            X_test[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "log_cols = ['MonthlyLoanPayment', 'TotalAssets', 'TotalLiabilities', 'NetWorth',\n",
    "            'LoanAmount', 'MonthlyDebtPayments', 'SavingsAccountBalance', 'CheckingAccountBalance']\n",
    "\n",
    "for col in log_cols:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = np.log1p(X_train[col])\n",
    "        X_test[col] = np.log1p(X_test[col])\n",
    "\n",
    "print(\"\\n Создаём дополнительные признаки...\")\n",
    "original_features = X_train.shape[1]\n",
    "\n",
    "important_numeric = ['Age', 'AnnualIncome', 'CreditScore', 'LoanAmount',\n",
    "                     'DebtToIncomeRatio', 'CreditCardUtilizationRate',\n",
    "                     'MonthlyIncome', 'MonthlyDebtPayments']\n",
    "\n",
    "for feat in important_numeric:\n",
    "    if feat in X_train.columns:\n",
    "        X_train[f'{feat}_squared'] = X_train[feat] ** 2\n",
    "        X_test[f'{feat}_squared'] = X_test[feat] ** 2\n",
    "\n",
    "if 'AnnualIncome' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['Income_to_Loan'] = X_train['AnnualIncome'] / (X_train['LoanAmount'] + 1)\n",
    "    X_test['Income_to_Loan'] = X_test['AnnualIncome'] / (X_test['LoanAmount'] + 1)\n",
    "\n",
    "if 'CreditScore' in X_train.columns and 'DebtToIncomeRatio' in X_train.columns:\n",
    "    X_train['Credit_Debt_Ratio'] = X_train['CreditScore'] * X_train['DebtToIncomeRatio']\n",
    "    X_test['Credit_Debt_Ratio'] = X_test['CreditScore'] * X_test['DebtToIncomeRatio']\n",
    "\n",
    "if 'MonthlyIncome' in X_train.columns and 'MonthlyDebtPayments' in X_train.columns:\n",
    "    X_train['Income_Debt_Ratio'] = X_train['MonthlyIncome'] / (X_train['MonthlyDebtPayments'] + 1)\n",
    "    X_test['Income_Debt_Ratio'] = X_test['MonthlyIncome'] / (X_test['MonthlyDebtPayments'] + 1)\n",
    "\n",
    "if 'Age' in X_train.columns and 'CreditScore' in X_train.columns:\n",
    "    X_train['Age_Credit_Interaction'] = X_train['Age'] * X_train['CreditScore']\n",
    "    X_test['Age_Credit_Interaction'] = X_test['Age'] * X_test['CreditScore']\n",
    "\n",
    "if 'TotalAssets' in X_train.columns and 'TotalLiabilities' in X_train.columns:\n",
    "    X_train['Assets_Liabilities_Ratio'] = X_train['TotalAssets'] / (X_train['TotalLiabilities'] + 1)\n",
    "    X_test['Assets_Liabilities_Ratio'] = X_test['TotalAssets'] / (X_test['TotalLiabilities'] + 1)\n",
    "\n",
    "if 'Age' in X_train.columns and 'AnnualIncome' in X_train.columns:\n",
    "    X_train['Age_Income'] = X_train['Age'] * X_train['AnnualIncome']\n",
    "    X_test['Age_Income'] = X_test['Age'] * X_test['AnnualIncome']\n",
    "\n",
    "if 'CreditScore' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['Credit_Loan'] = X_train['CreditScore'] * X_train['LoanAmount']\n",
    "    X_test['Credit_Loan'] = X_test['CreditScore'] * X_test['LoanAmount']\n",
    "\n",
    "if 'DebtToIncomeRatio' in X_train.columns and 'MonthlyIncome' in X_train.columns:\n",
    "    X_train['Debt_MonthlyIncome'] = X_train['DebtToIncomeRatio'] * X_train['MonthlyIncome']\n",
    "    X_test['Debt_MonthlyIncome'] = X_test['DebtToIncomeRatio'] * X_test['MonthlyIncome']\n",
    "\n",
    "if 'CreditCardUtilizationRate' in X_train.columns and 'CreditScore' in X_train.columns:\n",
    "    X_train['Utilization_Credit'] = X_train['CreditCardUtilizationRate'] * X_train['CreditScore']\n",
    "    X_test['Utilization_Credit'] = X_test['CreditCardUtilizationRate'] * X_test['CreditScore']\n",
    "\n",
    "if 'NetWorth' in X_train.columns and 'AnnualIncome' in X_train.columns:\n",
    "    X_train['NetWorth_Income'] = X_train['NetWorth'] / (X_train['AnnualIncome'] + 1)\n",
    "    X_test['NetWorth_Income'] = X_test['NetWorth'] / (X_test['AnnualIncome'] + 1)\n",
    "\n",
    "if 'SavingsAccountBalance' in X_train.columns and 'CheckingAccountBalance' in X_train.columns:\n",
    "    X_train['Savings_Checking'] = X_train['SavingsAccountBalance'] + X_train['CheckingAccountBalance']\n",
    "    X_test['Savings_Checking'] = X_test['SavingsAccountBalance'] + X_test['CheckingAccountBalance']\n",
    "\n",
    "if 'MonthlyLoanPayment' in X_train.columns and 'MonthlyIncome' in X_train.columns:\n",
    "    X_train['Payment_Income_Ratio'] = X_train['MonthlyLoanPayment'] / (X_train['MonthlyIncome'] + 1)\n",
    "    X_test['Payment_Income_Ratio'] = X_train['MonthlyLoanPayment'] / (X_test['MonthlyIncome'] + 1)\n",
    "\n",
    "if 'Age' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['Age_Loan'] = X_train['Age'] * X_train['LoanAmount']\n",
    "    X_test['Age_Loan'] = X_test['Age'] * X_test['LoanAmount']\n",
    "\n",
    "if 'Age' in X_train.columns and 'DebtToIncomeRatio' in X_train.columns:\n",
    "    X_train['Age_Debt'] = X_train['Age'] * X_train['DebtToIncomeRatio']\n",
    "    X_test['Age_Debt'] = X_test['Age'] * X_test['DebtToIncomeRatio']\n",
    "\n",
    "if 'AnnualIncome' in X_train.columns and 'DebtToIncomeRatio' in X_train.columns:\n",
    "    X_train['Income_Debt_Product'] = X_train['AnnualIncome'] * X_train['DebtToIncomeRatio']\n",
    "    X_test['Income_Debt_Product'] = X_test['AnnualIncome'] * X_test['DebtToIncomeRatio']\n",
    "\n",
    "if 'CreditScore' in X_train.columns and 'CreditCardUtilizationRate' in X_train.columns:\n",
    "    X_train['Credit_Utilization_Product'] = X_train['CreditScore'] * X_train['CreditCardUtilizationRate']\n",
    "    X_test['Credit_Utilization_Product'] = X_test['CreditScore'] * X_test['CreditCardUtilizationRate']\n",
    "    print(f\"  Добавлен признак: Credit_Utilization_Product\")\n",
    "\n",
    "if 'MonthlyIncome' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['MonthlyIncome_Loan_Ratio'] = X_train['MonthlyIncome'] / (X_train['LoanAmount'] + 1)\n",
    "    X_test['MonthlyIncome_Loan_Ratio'] = X_test['MonthlyIncome'] / (X_test['LoanAmount'] + 1)\n",
    "\n",
    "if 'TotalAssets' in X_train.columns and 'AnnualIncome' in X_train.columns:\n",
    "    X_train['Assets_Income_Ratio'] = X_train['TotalAssets'] / (X_train['AnnualIncome'] + 1)\n",
    "    X_test['Assets_Income_Ratio'] = X_test['TotalAssets'] / (X_test['AnnualIncome'] + 1)\n",
    "\n",
    "if 'NetWorth' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['NetWorth_Loan_Ratio'] = X_train['NetWorth'] / (X_train['LoanAmount'] + 1)\n",
    "    X_test['NetWorth_Loan_Ratio'] = X_test['NetWorth'] / (X_test['LoanAmount'] + 1)\n",
    "\n",
    "if 'MonthlyDebtPayments' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['Debt_Loan_Ratio'] = X_train['MonthlyDebtPayments'] / (X_train['LoanAmount'] + 1)\n",
    "    X_test['Debt_Loan_Ratio'] = X_test['MonthlyDebtPayments'] / (X_test['LoanAmount'] + 1)\n",
    "\n",
    "if 'SavingsAccountBalance' in X_train.columns and 'LoanAmount' in X_train.columns:\n",
    "    X_train['Savings_Loan_Ratio'] = X_train['SavingsAccountBalance'] / (X_train['LoanAmount'] + 1)\n",
    "    X_test['Savings_Loan_Ratio'] = X_test['SavingsAccountBalance'] / (X_test['LoanAmount'] + 1)\n",
    "\n",
    "if 'CheckingAccountBalance' in X_train.columns and 'MonthlyIncome' in X_train.columns:\n",
    "    X_train['Checking_Income_Ratio'] = X_train['CheckingAccountBalance'] / (X_train['MonthlyIncome'] + 1)\n",
    "    X_test['Checking_Income_Ratio'] = X_test['CheckingAccountBalance'] / (X_test['MonthlyIncome'] + 1)\n",
    "\n",
    "if 'TotalLiabilities' in X_train.columns and 'MonthlyIncome' in X_train.columns:\n",
    "    X_train['Liabilities_Income_Ratio'] = X_train['TotalLiabilities'] / (X_train['MonthlyIncome'] + 1)\n",
    "    X_test['Liabilities_Income_Ratio'] = X_test['TotalLiabilities'] / (X_test['MonthlyIncome'] + 1)\n",
    "\n",
    "if 'CreditScore' in X_train.columns and 'Age' in X_train.columns:\n",
    "    X_train['Credit_Age_Product'] = X_train['CreditScore'] * X_train['Age']\n",
    "    X_test['Credit_Age_Product'] = X_test['CreditScore'] * X_test['Age']\n",
    "\n",
    "if 'AnnualIncome' in X_train.columns and 'CreditScore' in X_train.columns:\n",
    "    X_train['Income_Credit_Product'] = X_train['AnnualIncome'] * X_train['CreditScore']\n",
    "    X_test['Income_Credit_Product'] = X_test['AnnualIncome'] * X_test['CreditScore']\n",
    "\n",
    "if 'DebtToIncomeRatio' in X_train.columns and 'CreditCardUtilizationRate' in X_train.columns:\n",
    "    X_train['Debt_Utilization_Product'] = X_train['DebtToIncomeRatio'] * X_train['CreditCardUtilizationRate']\n",
    "    X_test['Debt_Utilization_Product'] = X_test['DebtToIncomeRatio'] * X_test['CreditCardUtilizationRate']\n",
    "\n",
    "if 'MonthlyLoanPayment' in X_train.columns and 'CreditScore' in X_train.columns:\n",
    "    X_train['Payment_Credit_Product'] = X_train['MonthlyLoanPayment'] * X_train['CreditScore']\n",
    "    X_test['Payment_Credit_Product'] = X_test['MonthlyLoanPayment'] * X_test['CreditScore']\n",
    "\n",
    "if 'AnnualIncome' in X_train.columns:\n",
    "    X_train['Income_sqrt'] = np.sqrt(X_train['AnnualIncome'])\n",
    "    X_test['Income_sqrt'] = np.sqrt(X_test['AnnualIncome'])\n",
    "\n",
    "if 'LoanAmount' in X_train.columns:\n",
    "    X_train['Loan_sqrt'] = np.sqrt(X_train['LoanAmount'])\n",
    "    X_test['Loan_sqrt'] = np.sqrt(X_test['LoanAmount'])\n",
    "\n",
    "if 'TotalAssets' in X_train.columns:\n",
    "    X_train['Assets_sqrt'] = np.sqrt(X_train['TotalAssets'])\n",
    "    X_test['Assets_sqrt'] = np.sqrt(X_test['TotalAssets'])\n",
    "\n",
    "important_for_cube = ['CreditScore', 'DebtToIncomeRatio', 'Age']\n",
    "for feat in important_for_cube:\n",
    "    if feat in X_train.columns:\n",
    "        X_train[f'{feat}_cubed'] = X_train[feat] ** 3\n",
    "        X_test[f'{feat}_cubed'] = X_test[feat] ** 3\n",
    "        print(f\"  Добавлен признак: {feat}_cubed\")\n",
    "\n",
    "log_important = ['CreditScore', 'DebtToIncomeRatio', 'Age', 'CreditCardUtilizationRate']\n",
    "for feat in log_important:\n",
    "    if feat in X_train.columns and f'{feat}_log' not in X_train.columns:\n",
    "        # Используем log1p для избежания проблем с нулями\n",
    "        X_train[f'{feat}_log'] = np.log1p(np.abs(X_train[feat]))\n",
    "        X_test[f'{feat}_log'] = np.log1p(np.abs(X_test[feat]))\n",
    "        print(f\"  Добавлен признак: {feat}_log\")\n",
    "\n",
    "print(f\"Итого признаков после FE: {X_train.shape[1]}\")\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nЧисленных признаков: {len(numeric_cols)}\")\n",
    "print(f\"Категориальных признаков: {len(categorical_cols)}\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    # Кодируем категориальные признаки\n",
    "    X_train_cat = ohe.fit_transform(X_train[categorical_cols])\n",
    "    X_test_cat = ohe.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Создаем DataFrame для категориальных признаков\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "    X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "    X_test_cat_df = pd.DataFrame(X_test_cat, columns=cat_feature_names, index=X_test.index)\n",
    "\n",
    "    # Объединяем с численными признаками\n",
    "    X_train = pd.concat([X_train[numeric_cols], X_train_cat_df], axis=1)\n",
    "    X_test = pd.concat([X_test[numeric_cols], X_test_cat_df], axis=1)\n",
    "\n",
    "    print(f\"  После OneHotEncoder: {X_train.shape[1]} признаков\")\n",
    "\n",
    "X_train_arr = X_train.values.astype(np.float64)\n",
    "X_test_arr = X_test.values.astype(np.float64)\n",
    "\n",
    "if np.isinf(X_train_arr).any():\n",
    "    X_train_arr = np.nan_to_num(X_train_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "if np.isinf(X_test_arr).any():\n",
    "    X_test_arr = np.nan_to_num(X_test_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "normalizer = DataNormalizer(method='zscore')\n",
    "X_train_normalized = normalizer.fit_transform(X_train_arr)\n",
    "X_test_normalized = normalizer.transform(X_test_arr)\n",
    "\n",
    "if np.isnan(X_train_normalized).any():\n",
    "    X_train_normalized = np.nan_to_num(X_train_normalized, nan=0.0)\n",
    "    X_test_normalized = np.nan_to_num(X_test_normalized, nan=0.0)\n",
    "\n",
    "print(f\"\\nИтоговые размеры:\")\n",
    "print(f\"X_train_normalized: {X_train_normalized.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test_normalized: {X_test_normalized.shape}\")\n",
    "\n",
    "correlations = []\n",
    "for i in range(X_train_normalized.shape[1]):\n",
    "    corr = np.corrcoef(X_train_normalized[:, i], y_train)[0, 1]\n",
    "    correlations.append(abs(corr) if not np.isnan(corr) else 0)\n",
    "\n",
    "correlations = np.array(correlations)\n",
    "best_n = 85  # По умолчанию 85\n",
    "best_mse_fs = float('inf')\n",
    "results_fs = []\n",
    "\n",
    "for n in range(80, 98):\n",
    "    if n > X_train_normalized.shape[1]:\n",
    "        n = X_train_normalized.shape[1]\n",
    "\n",
    "    top_idx = np.argsort(correlations)[-n:][::-1]\n",
    "    X_temp = X_train_normalized[:, top_idx]\n",
    "\n",
    "    model_temp = LinearRegressionCustom(method='analytical')\n",
    "    model_temp.fit(X_temp, y_train)\n",
    "    y_pred_temp = model_temp.predict(X_temp)\n",
    "    mse_temp = mse_custom(y_train, y_pred_temp)\n",
    "\n",
    "    results_fs.append((n, mse_temp))\n",
    "    print(f\"  n={n:3d} признаков: MSE = {mse_temp:.4f}\")\n",
    "\n",
    "    if mse_temp < best_mse_fs:\n",
    "        best_mse_fs = mse_temp\n",
    "        best_n = n\n",
    "\n",
    "print(f\"\\n Лучшее количество признаков: {best_n}, MSE: {best_mse_fs:.4f}\")\n",
    "\n",
    "top_features_idx = np.argsort(correlations)[-best_n:][::-1]\n",
    "X_train_normalized = X_train_normalized[:, top_features_idx]\n",
    "X_test_normalized = X_test_normalized[:, top_features_idx]\n",
    "\n",
    "print(f\"Отобрано {best_n} лучших признаков из {len(correlations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7b24244e7bccb",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade62ce74a34a772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.794789Z",
     "start_time": "2025-12-02T18:48:31.714359Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# 1. No regularization\n",
    "model1 = LinearRegressionCustom(method='analytical')\n",
    "model1.fit(X_train_normalized, y_train)\n",
    "y_pred1 = model1.predict(X_train_normalized)\n",
    "mse1 = mse_custom(y_train, y_pred1)\n",
    "results.append(('No regularization', mse1, model1, X_train_normalized, X_test_normalized))\n",
    "print(f\"1. No regularization: MSE = {mse1:.4f}\")\n",
    "\n",
    "# 2. With L2 regularization (Ridge) - as in lab1.ipynb\n",
    "model2 = LinearRegressionCustom(method='analytical', regularization='l2', lambda_reg=0.1)\n",
    "model2.fit(X_train_normalized, y_train)\n",
    "y_pred2 = model2.predict(X_train_normalized)\n",
    "mse2 = mse_custom(y_train, y_pred2)\n",
    "results.append(('Ridge (alpha=0.1)', mse2, model2, X_train_normalized, X_test_normalized))\n",
    "print(f\"2. Ridge (alpha=0.1): MSE = {mse2:.4f}\")\n",
    "\n",
    "# 3. With L2 regularization (smaller alpha)\n",
    "model3 = LinearRegressionCustom(method='analytical', regularization='l2', lambda_reg=0.01)\n",
    "model3.fit(X_train_normalized, y_train)\n",
    "y_pred3 = model3.predict(X_train_normalized)\n",
    "mse3 = mse_custom(y_train, y_pred3)\n",
    "results.append(('Ridge (alpha=0.01)', mse3, model3, X_train_normalized, X_test_normalized))\n",
    "print(f\"3. Ridge (alpha=0.01): MSE = {mse3:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "results.sort(key=lambda x: x[1])\n",
    "best_name, best_mse, best_model, best_X_train, best_X_test = results[0]\n",
    "\n",
    "print(f\"\\nBEST MODEL: {best_name}\")\n",
    "print(f\"   MSE on train: {best_mse:.4f}\")\n",
    "\n",
    "final_model = best_model\n",
    "X_train_final = best_X_train\n",
    "X_test_final = best_X_test\n",
    "\n",
    "y_train_pred = final_model.predict(X_train_final)\n",
    "\n",
    "train_mse = mse_custom(y_train, y_train_pred)\n",
    "train_mae = mae_custom(y_train, y_train_pred)\n",
    "train_r2 = r2_custom(y_train, y_train_pred)\n",
    "\n",
    "print(f\"MSE:  {train_mse:.4f}\")\n",
    "print(f\"MAE:  {train_mae:.4f}\")\n",
    "print(f\"R²:   {train_r2:.4f}\")\n",
    "if np.all(y_train != 0):\n",
    "    train_mape = mape_custom(y_train, y_train_pred)\n",
    "    print(f\"MAPE: {train_mape:.4f}%\")\n",
    "\n",
    "y_test_pred = final_model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a919f3414699a00",
   "metadata": {},
   "source": [
    "# Создание submissions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739382bae2c38ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:31.844962Z",
     "start_time": "2025-12-02T18:48:31.821085Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids if test_ids is not None else range(len(y_test_pred)),\n",
    "    'RiskScore': y_test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfead566841ac20a",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa71d7a752ef57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:48:58.160386Z",
     "start_time": "2025-12-02T18:48:31.858261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot predictions vs actual values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Scatter plot\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.5, s=10)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()],\n",
    "             'r--', lw=2, label='Perfect line')\n",
    "axes[0].set_xlabel('Actual values')\n",
    "axes[0].set_ylabel('Predicted values')\n",
    "axes[0].set_title('Predictions vs Actual values (Train)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals = y_train - y_train_pred\n",
    "axes[1].scatter(y_train_pred, residuals, alpha=0.5, s=10)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted values')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual analysis')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL COMPARISON OF METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "# Analytical\n",
    "model_analytical = LinearRegressionCustom(method='analytical')\n",
    "model_analytical.fit(X_train_normalized, y_train)\n",
    "y_pred_analytical = model_analytical.predict(X_train_normalized)\n",
    "comparison_results.append({\n",
    "    'Method': 'Analytical',\n",
    "    'MSE': mse_custom(y_train, y_pred_analytical),\n",
    "    'MAE': mae_custom(y_train, y_pred_analytical),\n",
    "    'R²': r2_custom(y_train, y_pred_analytical),\n",
    "    'MAPE': mape_custom(y_train, y_pred_analytical)\n",
    "})\n",
    "\n",
    "# Gradient Descent\n",
    "model_gd = LinearRegressionCustom(method='gradient_descent', learning_rate=0.01, n_iterations=2000)\n",
    "model_gd.fit(X_train_normalized, y_train)\n",
    "y_pred_gd = model_gd.predict(X_train_normalized)\n",
    "comparison_results.append({\n",
    "    'Method': 'Gradient Descent',\n",
    "    'MSE': mse_custom(y_train, y_pred_gd),\n",
    "    'MAE': mae_custom(y_train, y_pred_gd),\n",
    "    'R²': r2_custom(y_train, y_pred_gd),\n",
    "    'MAPE': mape_custom(y_train, y_pred_gd)\n",
    "})\n",
    "\n",
    "# SGD\n",
    "model_sgd = LinearRegressionCustom(method='sgd', learning_rate=0.01, n_iterations=2000, batch_size=32)\n",
    "model_sgd.fit(X_train_normalized, y_train)\n",
    "y_pred_sgd = model_sgd.predict(X_train_normalized)\n",
    "comparison_results.append({\n",
    "    'Method': 'SGD',\n",
    "    'MSE': mse_custom(y_train, y_pred_sgd),\n",
    "    'MAE': mae_custom(y_train, y_pred_sgd),\n",
    "    'R²': r2_custom(y_train, y_pred_sgd),\n",
    "    'MAPE': mape_custom(y_train, y_pred_sgd)\n",
    "})\n",
    "\n",
    "# Sklearn\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_train_normalized, y_train)\n",
    "y_pred_sklearn = sklearn_model.predict(X_train_normalized)\n",
    "comparison_results.append({\n",
    "    'Method': 'Sklearn',\n",
    "    'MSE': mean_squared_error(y_train, y_pred_sklearn),\n",
    "    'MAE': mean_absolute_error(y_train, y_pred_sklearn),\n",
    "    'R²': r2_score(y_train, y_pred_sklearn),\n",
    "    'MAPE': mape_custom(y_train, y_pred_sklearn)\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n MAIN METRIC:\")\n",
    "print(f\"MSE on training set: {mse_custom(y_train, y_train_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
